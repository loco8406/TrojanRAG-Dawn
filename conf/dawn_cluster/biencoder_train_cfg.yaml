# Dawn Cluster (Cambridge HPC) Biencoder Training Configuration
# Hardware: Intel Xeon Platinum 8368Q + Intel PVC GPUs
# Partition: pvc9

defaults:
  - encoder: hf_bert
  - train: biencoder_dawn
  - datasets: encoder_train_default

name: dpr_dawn

hydra:
  run:
    dir: outputs/${name}/train

train_datasets:
dev_datasets:
output_dir:
train_sampling_rates:
loss_scale_factors:

# Whether to lower case the input text. Set True for uncased models, False for the cased ones.
do_lower_case: True

val_av_rank_start_epoch: 30
seed: 12345
checkpoint_file_name: dpr_biencoder_dawn

# A trained bi-encoder checkpoint file to initialize the model
model_file:

# Distributed training config for Dawn cluster
local_rank: -1
global_loss_buf_sz: 592000

# Intel XPU device config - use 'xpu' for Intel GPUs
device: xpu

distributed_world_size:
distributed_port:
distributed_init_method:

# Intel XPU settings - no CUDA
no_cuda: True
n_gpu:

# Mixed precision - use bf16 for Intel PVC (better support than fp16)
fp16: False
bf16: True

# Intel Extension for PyTorch (IPEX) handles mixed precision
# No Apex needed for Intel GPUs
fp16_opt_level:

# tokens which won't be split by tokenizer
special_tokens:

ignore_checkpoint_offset: False
ignore_checkpoint_optimizer: False
ignore_checkpoint_lr: False

# set to >1 to enable multiple query encoders
multi_q_encoder: False

# Set to True to reduce memory footprint for DDP mode
local_shards_dataloader: False

exclude_ptb: False
neg_only: False
